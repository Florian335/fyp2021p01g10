{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Group 10 - First Year Project\n",
    "### Data Science at ITU\n",
    "## Project 1 - Road collisions analysis 2021 "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The first project of Data Science's second semester required us to inform various city leaders around the United Kingdom about traffic fatalities and injuries; and give some insight for urban transport planning. This jupyter notebook presents Group 10's exploration of 2019 UK road collision data with complimentary analysis, visualisation and findings with relation to the city of Sheffield.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Task 0 - Data filtering and cleaning\n",
    "## Loading data\n",
    "Our first task invovles loading our 3 csv files (downloaded from https://data.gov.uk/dataset/road-accidents-safety-data on the 4th January 2021) into a traversable data structure we can start working with; such as a dictionary. We will then need to start the process of filtering and cleaning our data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {}\n",
    "\n",
    "TITLES = ['accidents', 'casualties', 'vehicles'] # Capitalisation is the standard for constants"
   ]
  },
  {
   "source": [
    "Pandas has a convinient method for reading in csv files and storing the data in a DataFrame structure offers flexibility."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['accidents'] = pd.read_csv(\"../data/raw/Road Safety Data - Accidents 2019.csv\")\n",
    "raw_data['casualties'] = pd.read_csv(\"../data/raw/Road Safety Data - Casualties 2019.csv\")\n",
    "raw_data['vehicles'] = pd.read_csv(\"../data/raw/Road Safety Data- Vehicles 2019.csv\") # File name missing a space before hyphen "
   ]
  },
  {
   "source": [
    "for TITLE in TITLES:\n",
    "    print(TITLE + \"\\tDataFrame shape: \" + str(raw_data[TITLE].shape))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accidents\tDataFrame shape: (117536, 32)\ncasualties\tDataFrame shape: (153158, 16)\nvehicles\tDataFrame shape: (216381, 23)\n"
     ]
    }
   ]
  },
  {
   "source": [
    " ### Data type insight?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "source": [
    "## Locating our city\n",
    "With our data loaded into a dictionary of DataFrames, we needed to locate the accidents that occured in Sheffield. To do this we made a mask identifying which accidents occured in the local district authority 215.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheffield_mask = (raw_data['accidents'][\"Local_Authority_(District)\"] == 215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      Accident_Index  Location_Easting_OSGR  Location_Northing_OSGR  \\\n",
       "44673  2019140805407               429140.0                381931.0   \n",
       "44674  2019140805409               434290.0                385121.0   \n",
       "44676  2019140805414               435393.0                391745.0   \n",
       "44677  2019140805567               433949.0                396778.0   \n",
       "44680  2019140805955               433662.0                389819.0   \n",
       "\n",
       "       Longitude   Latitude  Police_Force  Accident_Severity  \\\n",
       "44673  -1.563884  53.333509            14                  2   \n",
       "44674  -1.486208  53.361875            14                  3   \n",
       "44676  -1.468895  53.421340            14                  1   \n",
       "44677  -1.490081  53.466672            14                  2   \n",
       "44680  -1.495146  53.404142            14                  3   \n",
       "\n",
       "       Number_of_Vehicles  Number_of_Casualties        Date  ...  \\\n",
       "44673                   2                     1  01/01/2019  ...   \n",
       "44674                   2                     1  01/01/2019  ...   \n",
       "44676                   1                     1  01/01/2019  ...   \n",
       "44677                   2                     1  01/01/2019  ...   \n",
       "44680                   2                     1  03/01/2019  ...   \n",
       "\n",
       "       Pedestrian_Crossing-Human_Control  \\\n",
       "44673                                  0   \n",
       "44674                                  0   \n",
       "44676                                  0   \n",
       "44677                                  0   \n",
       "44680                                  0   \n",
       "\n",
       "      Pedestrian_Crossing-Physical_Facilities  Light_Conditions  \\\n",
       "44673                                       0                 1   \n",
       "44674                                       0                 4   \n",
       "44676                                       1                 4   \n",
       "44677                                       0                 1   \n",
       "44680                                       0                 1   \n",
       "\n",
       "      Weather_Conditions  Road_Surface_Conditions  Special_Conditions_at_Site  \\\n",
       "44673                  1                        2                           0   \n",
       "44674                  1                        1                           0   \n",
       "44676                  1                        1                           0   \n",
       "44677                  1                        1                           0   \n",
       "44680                  1                        1                           0   \n",
       "\n",
       "       Carriageway_Hazards  Urban_or_Rural_Area  \\\n",
       "44673                    0                    2   \n",
       "44674                    0                    1   \n",
       "44676                    0                    1   \n",
       "44677                    0                    1   \n",
       "44680                    0                    1   \n",
       "\n",
       "       Did_Police_Officer_Attend_Scene_of_Accident  LSOA_of_Accident_Location  \n",
       "44673                                            1                  E01007926  \n",
       "44674                                            1                  E01008052  \n",
       "44676                                            1                  E01008123  \n",
       "44677                                            1                  E01007901  \n",
       "44680                                            2                  E01008093  \n",
       "\n",
       "[5 rows x 32 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Accident_Index</th>\n      <th>Location_Easting_OSGR</th>\n      <th>Location_Northing_OSGR</th>\n      <th>Longitude</th>\n      <th>Latitude</th>\n      <th>Police_Force</th>\n      <th>Accident_Severity</th>\n      <th>Number_of_Vehicles</th>\n      <th>Number_of_Casualties</th>\n      <th>Date</th>\n      <th>...</th>\n      <th>Pedestrian_Crossing-Human_Control</th>\n      <th>Pedestrian_Crossing-Physical_Facilities</th>\n      <th>Light_Conditions</th>\n      <th>Weather_Conditions</th>\n      <th>Road_Surface_Conditions</th>\n      <th>Special_Conditions_at_Site</th>\n      <th>Carriageway_Hazards</th>\n      <th>Urban_or_Rural_Area</th>\n      <th>Did_Police_Officer_Attend_Scene_of_Accident</th>\n      <th>LSOA_of_Accident_Location</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44673</th>\n      <td>2019140805407</td>\n      <td>429140.0</td>\n      <td>381931.0</td>\n      <td>-1.563884</td>\n      <td>53.333509</td>\n      <td>14</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>01/01/2019</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>E01007926</td>\n    </tr>\n    <tr>\n      <th>44674</th>\n      <td>2019140805409</td>\n      <td>434290.0</td>\n      <td>385121.0</td>\n      <td>-1.486208</td>\n      <td>53.361875</td>\n      <td>14</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>01/01/2019</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>E01008052</td>\n    </tr>\n    <tr>\n      <th>44676</th>\n      <td>2019140805414</td>\n      <td>435393.0</td>\n      <td>391745.0</td>\n      <td>-1.468895</td>\n      <td>53.421340</td>\n      <td>14</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>01/01/2019</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>E01008123</td>\n    </tr>\n    <tr>\n      <th>44677</th>\n      <td>2019140805567</td>\n      <td>433949.0</td>\n      <td>396778.0</td>\n      <td>-1.490081</td>\n      <td>53.466672</td>\n      <td>14</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>01/01/2019</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>E01007901</td>\n    </tr>\n    <tr>\n      <th>44680</th>\n      <td>2019140805955</td>\n      <td>433662.0</td>\n      <td>389819.0</td>\n      <td>-1.495146</td>\n      <td>53.404142</td>\n      <td>14</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>03/01/2019</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>E01008093</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "sheffield_data = {}\n",
    "\n",
    "sheffield_data['accidents'] = raw_data['accidents'][sheffield_mask]\n",
    "sheffield_data['accidents'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(909, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "sheffield_data['accidents'].shape"
   ]
  },
  {
   "source": [
    "We can now see that there are 909 records of road traffic accidents occuring in Sheffield over 2019. The next step was using the primary key (accident_index) of the accidents to find the accidents in Sheffield that each casualty and vehicle linked to, in order to complete our sheffield_data dictionary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "44673    2019140805407\n",
       "44674    2019140805409\n",
       "44676    2019140805414\n",
       "44677    2019140805567\n",
       "44680    2019140805955\n",
       "Name: Accident_Index, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "sheffield_data['accidents'][\"Accident_Index\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for TITLE in TITLES[1:]: sheffield_data[TITLE] = raw_data[TITLE][raw_data[TITLE]['Accident_Index'].isin(sheffield_data[\"accidents\"][\"Accident_Index\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sheffield accidents\tDataFrame shape: (909, 32)\nSheffield casualties\tDataFrame shape: (1191, 16)\nSheffield vehicles\tDataFrame shape: (1648, 23)\n"
     ]
    }
   ],
   "source": [
    "for TITLE in TITLES: print(\"Sheffield \" + TITLE + \"\\tDataFrame shape: \" + str(sheffield_data[TITLE].shape))"
   ]
  },
  {
   "source": [
    "## Relational data table model \n",
    "In terms of the structure of the three databases or data tables, the accidents table's primary key is used as a foreign key by both the casualties and vehicles data tables, creating a one-to-many link between the accidents and both the casualties and vehicles tables. From this data table structure, we can infer that multiple casualties and vehicles can be involved in a single accident; which makes sense logically."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Sanity check\n",
    "Performing a sanity check on our Sheffield road accident data is a critical first step before we can begin to think about further analysing or drawing conclusions from the data. We may also have to sanity check all the data if we wish to draw conclusions therefrom."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for empty strings in categorical fields  \n",
    "#Check for NULL values                          #DONE \n",
    "#Check duplicate records                        #DONE\n",
    "#Check non-linked records in secondary tables   "
   ]
  },
  {
   "source": [
    "### Checking for null values in our road accident dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accidents - Location_Easting_OSGR\t has 28 null values\n",
      "accidents - Location_Northing_OSGR\t has 28 null values\n",
      "accidents - Longitude\t has 28 null values\n",
      "accidents - Latitude\t has 28 null values\n",
      "accidents - Time\t has 63 null values\n",
      "accidents - LSOA_of_Accident_Location\t has 5714 null values\n"
     ]
    }
   ],
   "source": [
    "flag = False\n",
    "for TITLE in TITLES:\n",
    "    if raw_data[TITLE].isnull().values.any():\n",
    "        for column in list(raw_data[TITLE].columns):\n",
    "            nulls = sum(raw_data[TITLE][column].isnull())\n",
    "            if sum(raw_data[TITLE][column].isnull()):\n",
    "                print(TITLE + \" - \" + column + \"\\t has \" + str(nulls) + \" null values\")\n",
    "                flag = True\n",
    "if not flag: print(\"There are no null values in the dataset\")"
   ]
  },
  {
   "source": [
    "### Checking for null values in our sheffield dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are no null values in the dataset\n"
     ]
    }
   ],
   "source": [
    "flag = False\n",
    "for TITLE in TITLES:\n",
    "    if sheffield_data[TITLE].isnull().values.any():\n",
    "        for column in list(sheffield_data[TITLE].columns):\n",
    "            nulls = sum(sheffield_data[TITLE][column].isnull())\n",
    "            if sum(sheffield_data[TITLE][column].isnull()):\n",
    "                print(TITLE + \" - \" + column + \"\\t has \" + str(nulls) + \" null values\")\n",
    "                flag = True\n",
    "if not flag: print(\"There are no null values in the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No repeated indexes\n"
     ]
    }
   ],
   "source": [
    "if len(sheffield_data[\"accidents\"][\"Accident_Index\"]) == len((sheffield_data[\"accidents\"][\"Accident_Index\"].unique())):\n",
    "    print(\"No repeated indexes\")\n",
    "else: print(\"Repeated indexes detected\")"
   ]
  },
  {
   "source": [
    "## Numerical summary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Five Number Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Histogram"
   ]
  },
  {
   "source": [
    "# Task 1 - Single variable analysis\n",
    "### Report the frequency of road collisions in your city for \n",
    "\n",
    "1. different age groups \n",
    "2. in different times (during the day, the week, or year)\n",
    "3. and for differences in one other condition.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Task 2 - Associations\n",
    "### Research whether there is a significant statistical association in your city, either\n",
    "1. between some vehicle attributes and accident circumstances, or \n",
    "2. between some casualty attributes and accident circumstances. \n",
    "\n",
    "Report whether there is a statistically significant association between such variables or not, together with the appropriate statistical metric(s).\n",
    " \n",
    "Discuss why this association, or the lack of\n",
    "this association, is relevant for urban/transport planning."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Task 3 - Map visualization\n",
    "Visualize the reported collisions on a map of your city. Make a visual distinction between different\n",
    "classes of casualty severity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Task 4: Open question\n",
    "Use the data to formulate, motivate, answer, and discuss another research question of your choice.\n",
    "For example, compare your city to the whole UK, or investigate different collision participants (bicycle\n",
    "vs car, bicycle-motored two-wheeler, pedestrian vs car, car vs car,…), or compare the age distribution\n",
    "of casualties to the existing age distribution, or rank/compare how problematic different driver\n",
    "demographics are (young/old male/female),…"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}